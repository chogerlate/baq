name: Get WandB Runs
on:
  pull_request:

jobs:
  get-runs:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
        
      - name: Debug - Show PR head SHA
        run: echo "Using commit SHA: ${{ github.event.pull_request.head.sha }}"
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install wandb
        run: pip install wandb
        
      - name: Create Python script
        run: |
          cat > wandb_script.py << 'SCRIPT_EOF'
          import os
          import wandb
          
          entity = os.environ["WANDB_ENTITY"]
          project = os.environ["WANDB_PROJECT"]
          sha = os.environ["TARGET_SHA"]
          
          print(f"Target SHA: {sha}")
          
          api = wandb.Api()
          runs = api.runs(f"{entity}/{project}")
          
          print(f"Total runs fetched: {len(runs)}")
          
          for r in runs:
              print(f"Run: {r.name}, Commit: {r.commit}")
          
          # Filter runs that match the target SHA (exact match)
          exact_matched = [r for r in runs if r.commit == sha]
          
          # Also try partial match for the first 7 characters (common Git short SHA)
          short_sha = sha[:7] if len(sha) >= 7 else sha
          partial_matched = [r for r in runs if r.commit and r.commit.startswith(short_sha)]
          
          print(f"Exact matched runs: {len(exact_matched)}")
          print(f"Partial matched runs: {len(partial_matched)}")
          
          # If no matches found, show all recent runs anyway
          matched_runs = exact_matched if exact_matched else (partial_matched if partial_matched else runs)
          
          def get_performance_emoji(accuracy):
              if accuracy is None:
                  return "‚ùì"
              if accuracy >= 0.95:
                  return "üèÜ"
              elif accuracy >= 0.90:
                  return "ü•á"
              elif accuracy >= 0.85:
                  return "ü•à"
              elif accuracy >= 0.80:
                  return "ü•â"
              elif accuracy >= 0.70:
                  return "üëç"
              else:
                  return "‚ö†Ô∏è"
          
          def format_runtime(runtime_seconds):
              if runtime_seconds is None:
                  return "N/A"
              if runtime_seconds < 60:
                  return f"{runtime_seconds:.1f}s"
              elif runtime_seconds < 3600:
                  return f"{runtime_seconds/60:.1f}m"
              else:
                  return f"{runtime_seconds/3600:.1f}h"
          
          with open("wandb_summary.md", "w") as f:
              f.write(f"# ü§ñ Model Performance Report\n")
              f.write(f"**Commit:** `{sha[:8]}...` | **Total Runs:** {len(runs)}\n\n")
              
              if exact_matched:
                  f.write(f"## üéØ Model Performance (Exact Match: {len(exact_matched)} runs)\n\n")
              elif partial_matched:
                  f.write(f"## üéØ Model Performance (Partial Match: {len(partial_matched)} runs)\n\n")
              else:
                  f.write("## üìã Latest Model Performance\n")
                  f.write(f"*No runs found for commit `{sha[:8]}...`, showing latest model runs:*\n\n")
                  matched_runs = sorted(runs, key=lambda x: x.created_at, reverse=True)[:10]
              
              best_accuracy = 0
              best_model = None
              total_runtime = 0
              
              for run in matched_runs:
                  accuracy = run.summary.get('accuracy') or run.summary.get('best_val_acc') or run.summary.get('val_accuracy')
                  runtime = run.summary.get('_runtime')
                  
                  if accuracy and accuracy > best_accuracy:
                      best_accuracy = accuracy
                      best_model = run.name
                  
                  if runtime:
                      total_runtime += runtime
              
              if best_model and best_accuracy > 0:
                  f.write(f"üèÜ **Best Performer:** {best_model} ({best_accuracy:.3f} accuracy)\n")
                  f.write(f"‚è±Ô∏è **Total Training Time:** {format_runtime(total_runtime)}\n\n")
              
              f.write("| Model | Performance | Accuracy | Loss | Runtime | Status | Link |\n")
              f.write("|-------|-------------|----------|------|---------|--------|----- |\n")
              
              for run in matched_runs:
                  accuracy = run.summary.get('accuracy') or run.summary.get('best_val_acc') or run.summary.get('val_accuracy')
                  loss = run.summary.get('loss') or run.summary.get('best_val_loss') or run.summary.get('val_loss')
                  runtime = run.summary.get('_runtime')
                  
                  perf_emoji = get_performance_emoji(accuracy)
                  acc_str = f"{accuracy:.3f}" if accuracy is not None else "N/A"
                  loss_str = f"{loss:.4f}" if loss is not None else "N/A"
                  runtime_str = format_runtime(runtime)
                  
                  status_emoji = "‚úÖ" if run.state == "finished" else "üîÑ" if run.state == "running" else "‚ùå"
                  
                  f.write(f"| **{run.name}** | {perf_emoji} | {acc_str} | {loss_str} | {runtime_str} | {status_emoji} | [View]({run.url}) |\n")
              
              f.write(f"\nüìä **Performance Legend:**\n")
              f.write("üèÜ Excellent (95%+) | ü•á Great (90%+) | ü•à Good (85%+) | ü•â Fair (80%+) | üëç OK (70%+) | ‚ö†Ô∏è Needs Work\n\n")
              
              if matched_runs:
                  f.write(f"## üìà Detailed Metrics\n\n")
                  for run in matched_runs:
                      accuracy = run.summary.get('accuracy') or run.summary.get('best_val_acc') or run.summary.get('val_accuracy')
                      f.write(f"### {get_performance_emoji(accuracy)} {run.name}\n")
                      
                      core_metrics = {
                          "Accuracy": run.summary.get('accuracy') or run.summary.get('best_val_acc') or run.summary.get('val_accuracy'),
                          "Loss": run.summary.get('loss') or run.summary.get('best_val_loss') or run.summary.get('val_loss'),
                          "Training Accuracy": run.summary.get('train_accuracy'),
                          "Validation Accuracy": run.summary.get('val_accuracy'),
                          "Training Loss": run.summary.get('train_loss'),
                          "Validation Loss": run.summary.get('val_loss'),
                          "Runtime": run.summary.get('_runtime')
                      }
                      
                      metrics_found = False
                      for metric_name, value in core_metrics.items():
                          if value is not None:
                              metrics_found = True
                              if metric_name == "Runtime":
                                  f.write(f"- **{metric_name}:** {format_runtime(value)}\n")
                              elif isinstance(value, float):
                                  f.write(f"- **{metric_name}:** {value:.4f}\n")
                              else:
                                  f.write(f"- **{metric_name}:** {value}\n")
                      
                      if not metrics_found:
                          f.write("- *No metrics available*\n")
                      
                      f.write(f"- **Status:** {run.state}\n")
                      f.write(f"- **Commit:** `{run.commit}`\n")
                      f.write(f"- **Created:** {run.created_at}\n")
                      f.write(f"- **View Full Run:** [Click Here]({run.url})\n\n")
              
              f.write("---\n")
              f.write("*Generated by WandB GitHub Action* ü§ñ")
          
          print("Markdown file generated successfully")
          SCRIPT_EOF
          
      - name: Fetch W&B Runs and generate markdown
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          WANDB_ENTITY: ${{ secrets.WANDB_ENTITY }}
          WANDB_PROJECT: ${{ secrets.WANDB_PROJECT }}
          TARGET_SHA: ${{ github.event.pull_request.head.sha }}
        run: python wandb_script.py
        
      - name: Debug - Show generated markdown
        run: |
          echo "Generated markdown content:"
          cat wandb_summary.md
          
      - name: Install GitHub CLI
        run: |
          sudo apt update
          sudo apt install gh -y
          
      - name: Comment to PR
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          gh pr comment ${{ github.event.pull_request.number }} --body-file wandb_summary.md
